# Default configuration for RAG vs GraphRAG benchmark
# Based on paper: https://arxiv.org/abs/2502.11371

output_dir: "./benchmark_results/triplet_vs_vector"
cache_dir: "./cache"

dataset:
  name: "yixuantt/MultiHopRAG"
  max_samples: 1000  # null = use all samples

# LLM for generation and entity extraction
llm:
  api_key_env: "OPENAI_API_KEY"
  api_base: https://qwen-30b-a3.ai.alfaintra.net/v1  # set for OpenAI-compatible API, e.g., "https://api.example.com/v1"
  model: "Qwen3-Coder-30B-A3B-Instruct-FP8"
  temperature: 0.0
  max_tokens: 512

# Embedding model
embedding:
  api_key_env: "OPENAI_API_KEY"
  api_base: https://litellm-hub.infra.moscow.alfaintra.net/v1  # set for OpenAI-compatible API
  model: "hosted_vllm/BAAI/bge-m3"
  batch_size: 100

# Vector RAG settings (as in paper)
vector_rag:
  chunk_size: 256  # tokens
  chunk_overlap: 50
  top_k: 10

# GraphRAG v2 settings (community-based, self-contained)
graphrag:
  max_paths_per_chunk: 10
  max_cluster_size: 10
  local_search_top_k: 10
  num_workers: 4

# Evaluation settings
evaluation:
  normalize_answers: true
  case_sensitive: false

# Methods to run (comment out to skip)
methods:
  - vector_rag
  - graphrag_local
  - graphrag_global
  - hybrid_selection
  - hybrid_integration
