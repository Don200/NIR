# Default configuration for RAG vs GraphRAG benchmark
# Based on paper: https://arxiv.org/abs/2502.11371

output_dir: "./benchmark_results"
cache_dir: "./cache"

dataset:
  name: "yixuantt/MultiHopRAG"
  max_samples: null  # null = use all samples

# LLM for generation and entity extraction
llm:
  api_key_env: "OPENAI_API_KEY"
  api_base: null  # set for OpenAI-compatible API, e.g., "https://api.example.com/v1"
  model: "gpt-4o-mini"
  temperature: 0.0
  max_tokens: 512

# Embedding model
embedding:
  api_key_env: "OPENAI_API_KEY"
  api_base: null  # set for OpenAI-compatible API
  model: "text-embedding-ada-002"
  batch_size: 100

# Vector RAG settings (as in paper)
vector_rag:
  chunk_size: 256  # tokens
  chunk_overlap: 50
  top_k: 10

# GraphRAG v2 settings (community-based, self-contained)
graphrag:
  max_paths_per_chunk: 10
  max_cluster_size: 10
  local_search_top_k: 10

# Evaluation settings
evaluation:
  normalize_answers: true
  case_sensitive: false

# Methods to run (comment out to skip)
methods:
  - vector_rag
  - graphrag_local
  - graphrag_global
  - hybrid_selection
  - hybrid_integration
