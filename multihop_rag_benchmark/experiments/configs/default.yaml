# Default configuration for RAG vs GraphRAG benchmark
# Based on paper: https://arxiv.org/abs/2502.11371

output_dir: "./benchmark_results"
cache_dir: "./cache"

dataset:
  name: "yixuantt/MultiHopRAG"
  max_samples: null  # null = use all samples

# LLM for generation and entity extraction
llm:
  api_key_env: "OPENAI_API_KEY"
  api_base: null  # set for OpenAI-compatible API, e.g., "https://api.example.com/v1"
  model: "gpt-4o-mini"
  temperature: 0.0
  max_tokens: 512

# Embedding model
embedding:
  api_key_env: "OPENAI_API_KEY"
  api_base: null  # set for OpenAI-compatible API
  model: "text-embedding-ada-002"
  batch_size: 100

# Vector RAG settings (as in paper)
vector_rag:
  chunk_size: 256  # tokens
  chunk_overlap: 50
  top_k: 10

# KG-based GraphRAG settings (LlamaIndex approach)
kg_rag:
  max_triplets_per_chunk: 10
  include_original_text: true
  max_hops: 2

# Community-based GraphRAG settings (Microsoft GraphRAG)
community_rag:
  graphrag_root: "./graphrag_index"
  community_level: 2
  local_search_top_k: 10
  global_search_top_k: 5

# Evaluation settings
evaluation:
  normalize_answers: true
  case_sensitive: false

# Methods to run (comment out to skip)
methods:
  - vector_rag
  - kg_rag
  # - community_rag_local  # requires graphrag installation
  # - community_rag_global
  - hybrid_selection
  - hybrid_integration
